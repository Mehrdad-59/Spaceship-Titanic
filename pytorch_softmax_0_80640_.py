# -*- coding: utf-8 -*-
"""Spaceship Titanic _PyTorch_Softmax_0.80640_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lhuNMW1Kz1Z6T5jeu-I-coMALu1zu2LF
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from scipy.stats.mstats import gmean
import warnings
warnings.filterwarnings('ignore')

import gc

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2 # just added 
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2
    percent = 100 * (start_mem - end_mem) / start_mem
    print('Mem. usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'.format(start_mem, end_mem, percent))
    return df

"""### **Import Data**"""

train=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')

train.head(3)

train.info()

train.isna().sum()

for df in [train, test]:
  for col in ['CryoSleep','VIP']:
    df[col]=df[col].astype('bool')

for df in [train, test]:
  df.drop('Name', axis=1, inplace=True)

for df in [train, test]:
      reduce_mem_usage(df)

def Column_transform(df):
  df['Group']=df['PassengerId'].apply(lambda x: x.split('_')[0])
  #df['Group_no']=df['PassengerId'].apply(lambda x: x.split('_')[1])
  df['deck']=df[df['Cabin'].notnull()]['Cabin'].apply(lambda x: x.split('/')[0])
  df['deck_num']=df[df['Cabin'].notnull()]['Cabin'].apply(lambda x: x.split('/')[1])
  df['deck_side']=df[df['Cabin'].notnull()]['Cabin'].apply(lambda x: x.split('/')[2])
  df.drop('PassengerId', axis=1, inplace=True)
  #df.drop('Cabin', axis=1, inplace=True)
  return df

train_1=Column_transform(train)
test_1=Column_transform(test)

train_1.head(3)

gc.collect()

"""**Zero Age Adjusted & Age Missing Values**"""

def Age_adjust(train, test):
  test['Transported']=3
  df=pd.concat([train,test])
  mean_age=df.loc[(df['Age']!=0)&(~df['Age'].isnull()), 'Age'].astype(float).mean()
  df.loc[(df['Age']==0) | (df['Age'].isnull()), 'Age']=mean_age
    
  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

train_1, test_1=Age_adjust(train_1, test_1)

"""**Handling Missing values**"""

numeric_cols=['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']
def num_fillna(train_df, test_df):
  test_df['Transported']=3
  df=pd.concat([train_df,test_df])
  for col in numeric_cols:
    M=df[col].astype(float).mean()
    df[col]=df[col].fillna(M)
  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

train_2, test_2 = num_fillna(train_1, test_1)

train_2.isna().sum()

#cat_cols=['HomePlanet','CryoSleep','Destination','VIP','deck','deck_num','deck_side']
def cat_fillna (train_df, test_df):
  test_df['Transported']=3
  df=pd.concat([train_df,test_df])
  for col in cat_cols:
    df[col+"_fill"]=np.where(df[col].isnull(), 1, 0)
    fill=df[col].value_counts().reset_index().iloc[0,0]
    df[col]=df[col].fillna(fill)
  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

#train_3, test_3 = cat_fillna(train_2, test_2)

del train_1, test_1
gc.collect()

train_2['Transported']=train_2['Transported'].astype('bool')

"""## **EDA**

### **Correlation**
"""

sns.set_style(style='white')
corr=train_2.corr()
mask=np.triu(np.ones_like(corr, dtype=np.bool))
f, ax =plt.subplots(figsize=(15,10))
cmap = sns.diverging_palette(220, 10, as_cmap=True)
plt.title('Correlation Matrix', fontsize=18)
sns.heatmap(corr, cmap=cmap, mask=mask, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5}, annot=True)
plt.show()

"""### **Feature Engineering**"""

from sklearn.preprocessing import LabelEncoder

lbl_encode_cols=[col for col in train_2.columns if col not in ['Transported']]
for f in lbl_encode_cols:
        if train_2[f].dtype=='object' or test_2[f].dtype=='object':
            train_2[f] = train_2[f].fillna('unseen_before_label')
            test_2[f] = test_2[f].fillna('unseen_before_label')
            lbl = LabelEncoder()
            lbl.fit(list(train_2[f].values) + list(test_2[f].values))
            train_2[f] = lbl.transform(list(train_2[f].values))
            test_2[f] = lbl.transform(list(test_2[f].values))

train_2.isna().sum()

"""Total Billed"""

Billed_col=['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']
def total_billed(df, billed_col): 
  df['Total_billed']=df[billed_col].sum(axis=1)
  return df

train_3=total_billed(train_2, Billed_col)
test_3=total_billed(test_2, Billed_col)

train_3.columns

"""**FE** Billed"""

def FE_billed(train,test):
  test['Transported']=3
  df=pd.concat([train,test])
  df['avg_group']=df.groupby('Group')['Total_billed'].transform('mean')
  df['avg_Cabin']=df.groupby('Cabin')['Total_billed'].transform('mean')
  df['avg_homeplanet']=df.groupby('HomePlanet')['Total_billed'].transform('mean')
  df['avg_Destination']=df.groupby('Destination')['Total_billed'].transform('mean')
  df['avg_VIP']=df.groupby('VIP')['Total_billed'].transform('mean')
  df['avg_deck']=df.groupby('deck')['Total_billed'].transform('mean')
  df['avg_deck_side']=df.groupby('deck_side')['Total_billed'].transform('mean')
  
  df['med_group']=df.groupby('Group')['Total_billed'].transform('median')
  df['med_Cabin']=df.groupby('Cabin')['Total_billed'].transform('median')
  df['med_homeplanet']=df.groupby('HomePlanet')['Total_billed'].transform('median')
  df['med_Destination']=df.groupby('Destination')['Total_billed'].transform('median')
  df['med_VIP']=df.groupby('VIP')['Total_billed'].transform('median')
  df['med_deck']=df.groupby('deck')['Total_billed'].transform('median')
  df['med_deck_side']=df.groupby('deck_side')['Total_billed'].transform('median')
  
  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

train_4, test_4=FE_billed(train_3, test_3)

del train_2, test_2
gc.collect()

"""**Special Services Sum**"""

Special_col=['RoomService','Spa','VRDeck']
def FE_Special_Service(train,test):
  test['Transported']=3
  df=pd.concat([train,test])
  df['Special_service']=df[Special_col].sum(axis=1)

  df['Spec_avg_group']=df.groupby('Group')['Special_service'].transform('mean')
  df['Spec_avg_Cabin']=df.groupby('Cabin')['Special_service'].transform('mean')
  df['Spec_avg_homeplanet']=df.groupby('HomePlanet')['Special_service'].transform('mean')
  df['Spec_avg_Destination']=df.groupby('Destination')['Special_service'].transform('mean')
  df['Spec_avg_VIP']=df.groupby('VIP')['Special_service'].transform('mean')
  df['Spec_avg_deck']=df.groupby('deck')['Special_service'].transform('mean')
  df['Spec_avg_deck_side']=df.groupby('deck_side')['Special_service'].transform('mean')
  
  df['Spec_med_group']=df.groupby('Group')['Special_service'].transform('median')
  df['Spec_med_Cabin']=df.groupby('Cabin')['Special_service'].transform('median')
  df['Spec_med_homeplanet']=df.groupby('HomePlanet')['Special_service'].transform('median')
  df['Spec_med_Destination']=df.groupby('Destination')['Special_service'].transform('median')
  df['Spec_med_VIP']=df.groupby('VIP')['Special_service'].transform('median')
  df['Spec_med_deck']=df.groupby('deck')['Special_service'].transform('median')
  df['Spec_med_deck_side']=df.groupby('deck_side')['Special_service'].transform('median')

  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

train_5, test_5=FE_Special_Service(train_4, test_4)

"""**FE Transported**"""

#for df in [train_6,test_6]:
   #df['avg_HomePlanet_Trns']=train_6.groupby('HomePlanet')['Transported'].transform('mean')
   #df['avg_CryoSleep_Trns']=train_6.groupby('CryoSleep')['Transported'].transform('mean')
   #df['avg_Destination_Trns']=train_6.groupby('Destination')['Transported'].transform('mean')
   #df['avg_Group_Trns']=train_6.groupby('Group')['Transported'].transform('mean')
   #df['avg_Group_no_Trns']=train_6.groupby('Group_no')['Transported'].transform('mean')
   #df['avg_deck_Trns']=train_6.groupby('deck')['Transported'].transform('mean')
   #df['avg_deck_num_Trns']=train_6.groupby('deck_num')['Transported'].transform('mean')
   #df['avg_deck_side_Trns']=train_6.groupby('deck_side')['Transported'].transform('mean')

"""**FE-Age**"""

def Age_transported(train, test):
  test['Transported']=3
  df=pd.concat([train,test])
  mask_1=df['Age']<=20
  mask_2=(df['Age']>20) & (df['Age']<=40)
  mask_3=(df['Age']>40) & (df['Age']<=60)
  mask_4=(df['Age']>60)
  mean_mask_1=df.loc[mask_1, 'Transported'].mean()
  mean_mask_2=df.loc[mask_2, 'Transported'].mean()
  mean_mask_3=df.loc[mask_3, 'Transported'].mean()
  mean_mask_4=df.loc[mask_4, 'Transported'].mean()

  df.loc[mask_1, 'Age_transported']=mean_mask_1
  df.loc[mask_2, 'Age_transported']=mean_mask_2
  df.loc[mask_3, 'Age_transported']=mean_mask_3
  df.loc[mask_4, 'Age_transported']=mean_mask_4

  tr_fll=df[df['Transported']!=3]
  te_fll=df[df['Transported']==3].drop('Transported', axis=1)
  return tr_fll, te_fll

#train_7, test_7=Age_transported(train_6, test_6)

del train_3, test_3, train_4, test_4
gc.collect()

for df in [train_5, test_5]:
      reduce_mem_usage(df)

train_5.info()

train_5['Transported']=train_5['Transported'].astype('int')

X=train_5.drop('Transported', axis=1)
y=train_5['Transported']
X_test=test_5

X.shape

X_test.shape

"""**Scaling Numeric Columns for NN**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

Scaler=MinMaxScaler()
X=Scaler.fit_transform(X)
X_test=Scaler.transform(X_test)

"""**NN model with PyTorch**"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

torch.cuda.is_available()

X=torch.tensor(X, dtype=torch.float)
X_test=torch.tensor(X_test, dtype=torch.float)
y=torch.tensor(y).flatten().cuda()
y=y.type(torch.cuda.LongTensor)

X.shape

y.shape

X_test.shape

"""**Defining the Model**"""

from sklearn.metrics import accuracy_score

class TitanicModel(nn.Module):
  def __init__(self, in_sz, out_sz, layers, p):
    super().__init__()
    layerlist=[]
    for i in layers:
      layerlist.append(nn.Linear(in_sz,i))
      layerlist.append(nn.ReLU(inplace=True))
      layerlist.append(nn.BatchNorm1d(i))
      layerlist.append(nn.Dropout(p))
      in_sz=i
    layerlist.append(nn.Linear(layers[-1], out_sz))

    self.layers=nn.Sequential(*layerlist)
  
  def forward(self, x):
    x=self.layers(x)
    return x

in_sz=X.shape[1]
out_sz=2
layers=[200,150,100,100]
p=0.5
model=TitanicModel(in_sz, out_sz, layers, p)
gpumodel=model.cuda()

criterion=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(), lr=0.01)

"""**Train the model**"""

from sklearn.model_selection import StratifiedKFold
import time
start_time=time.time()
SEED=42
epochs=60
n_splits=5
skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)
y_pred=torch.tensor(np.zeros((X_test.shape[0],2))).cuda()
y=y.cpu()

for fold, (tr_idx, te_idx) in enumerate(skf.split(X,y)):
  kf_X_train=X[tr_idx].cuda()
  kf_y_train=y[tr_idx].cuda()
  kf_X_val=X[te_idx].cuda()
  kf_y_val=y[te_idx].cuda()
  print('Training fold:', fold+1)
  for i in range (epochs):
        i+=1
        oof_y_pred=gpumodel(kf_X_train)
        oof_y_val=gpumodel(kf_X_val)

        oof_Pred_loss=criterion(oof_y_pred,kf_y_train)
        oof_Val_loss=criterion(oof_y_val,kf_y_val)

        if i%10==0:
          print(f'epoch: {i:3}  loss: {oof_Pred_loss.item(): 8.6f}  val_loss: {oof_Val_loss.item(): 8.6f}')
        
        optimizer.zero_grad()
        oof_Pred_loss.backward()
        optimizer.step()
  with torch.no_grad() :
    X=X.cuda()
    X_test=X_test.cuda()
    y_train_pred=model(X)
    y_pred+=model(X_test)/n_splits
    y=y.cpu()
    y_train_pred=y_train_pred.cpu()
    y_train_pred_final=torch.argmax(y_train_pred, dim=1)
  print(f'fold {fold+1} Accuracy Score: {accuracy_score(y,y_train_pred_final): 8.6f}')
print(f'\nDuration:{time.time() - start_time:.0f} seconds')

y_pred_final=torch.argmax(y_pred, dim=1)
y_pred_final

y_pred_final=y_pred_final.cpu().detach().numpy()

y_pred_final=y_pred_final.reshape(-1,1).astype('bool')

y_pred_final.shape

submission=pd.read_csv('sample_submission.csv')

submission.head()

submission.drop('Transported', axis=1, inplace=True)

submission['Transported']=y_pred_final

submission.head()

submission.to_csv('submission.csv', index=False)